The goal of this study is to develop a comprehensive machine learning system that can effectively integrate numerical and image-based data to enhance the accuracy and personalization of alopecia intervention models. Alopecia, a recurrent dermatologic condition characterized by hair loss, requires advanced diagnostics, treatment, and individualized management, which the proposed multimodal learning framework aims to address. By combining patient demographics, medical history, and biochemical markers (numerical data) with high-resolution images of scalp and hair patterns (image data), the model seeks to uncover synergies between these distinct data types to improve predictions and tailor interventions more effectively. The datasets used in the study are divided into two categories: image data, which includes various alopecia patterns, and numerical data, which includes information on hair loss probabilities and baldness. The numerical datasets are composed of three sets containing 1,000, 7,917, and 400 entries, respectively. To ensure a balanced and enriched dataset for model training, the Synthetic Minority Over-sampling Technique (SMOTE) is applied to the smallest and largest datasets, increasing each to 8,000 entries. SMOTE generates new data points by interpolating between existing minority class examples, which helps balance the dataset without duplicating samples and reduces the risk of overfitting. The integration of numerical and image data is expected to significantly enhance the reliability, accuracy, and personalization of alopecia interventions.
